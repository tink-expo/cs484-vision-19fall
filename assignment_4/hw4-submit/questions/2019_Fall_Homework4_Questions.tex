%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% CS484 Written Question Template
%
% Acknowledgements:
% The original code is written by Prof. James Tompkin (james_tompkin@brown.edu).
% The second version is revised by Prof. Min H. Kim (minhkim@kaist.ac.kr).
%
% This is a LaTeX document. LaTeX is a markup language for producing 
% documents. Your task is to fill out this document, then to compile 
% it into a PDF document. 
%
% 
% TO COMPILE:
% > pdflatex thisfile.tex
%
% If you do not have LaTeX and need a LaTeX distribution:
% - Personal laptops (all common OS): www.latex-project.org/get/
% - We recommend latex compiler miktex (https://miktex.org/) for windows,
%   macTex (http://www.tug.org/mactex/) for macOS users.
%   And TeXstudio(http://www.texstudio.org/) for latex editor.
%   You should install both compiler and editor for editing latex.
%   The another option is Overleaf (https://www.overleaf.com/) which is 
%   an online latex editor.
%
% If you need help with LaTeX, please come to office hours. 
% Or, there is plenty of help online:
% https://en.wikibooks.org/wiki/LaTeX
%
% Good luck!
% Min and the CS484 staff
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% How to include two graphics on the same line:
% 
% \includegraphics[width=0.49\linewidth]{yourgraphic1.png}
% \includegraphics[width=0.49\linewidth]{yourgraphic2.png}
%
% How to include equations:
%
% \begin{equation}
% y = mx+c
% \end{equation}
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue]{hyperref}
\usepackage[a4paper,margin=1.5in]{geometry}
\usepackage{stackengine,graphicx}
\usepackage{fancyhdr}
\setlength{\headheight}{15pt}
\usepackage{microtype}
\usepackage{times}
\usepackage{amsmath}

% From https://ctan.org/pkg/matlab-prettifier
\usepackage[numbered,framed]{matlab-prettifier}

\frenchspacing
\setlength{\parindent}{0cm} % Default is 15pt.
\setlength{\parskip}{0.3cm plus1mm minus1mm}

\pagestyle{fancy}
\fancyhf{}
\lhead{Homework 4 Questions}
\rhead{CS 484}
\rfoot{\thepage}

\date{}

\title{\vspace{-1cm}Homework 4 Questions}


\begin{document}
\maketitle
\vspace{-3cm}
\thispagestyle{fancy}

\section*{Instructions}
\begin{itemize}
  \item 4 questions.
  \item Write code where appropriate.
  \item Feel free to include images or equations.
  \item Please make this document anonymous.
  \item \textbf{Please use only the space provided and keep the page breaks.} Please do not make new pages, nor remove pages. The document is a template to help grading.
  \item If you really need extra space, please use new pages at the end of the document and refer us to it in your answers.
\end{itemize}

\section*{Questions}

\paragraph{Q1:} Imagine we were tasked with designing a feature point which could match all of the following three pairs of images. Which real world phenomena and camera effects might cause us problems?
Use the MATLAB function \href{https://www.mathworks.com/help/images/ref/corner.html}{$corner$} to investigate. $corner(I,1000)$.

\emph{RISHLibrary} | \emph{Chase} | \emph{LaddObservatory}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{A1:} Your answer here.

\textbf{RISHLibrary} \\
\begin{figure}[!h]
    \centering
    \includegraphics[width=5cm]{RISHLibrary1_corner.jpg}
    \includegraphics[width=5cm]{RISHLibrary2_corner.jpg}
    \caption{Result of $corner(I,1000)$ on RISHLibrary1.jpg and RISHLibrary2.jpg each.}
\end{figure} \\
As shown in above figure, unlike RISHLibrary2.jpg, there are feet of human in RISHLibrary1.jpg, which is causing an occlusion. Also, unlike RISHLibrary1.jpg, there is a shadow in top right corner of RISHLibrary2.jpg. Occlusion by object and difference in illumination such as shadow are causing problem for detecting feature points. \\
Continued in \hyperlink{page.5}{page 5}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Please leave the pagebreak
\pagebreak
\paragraph{Q2:} In designing our feature point, what characteristics might we wish it to have? Describe the fundamental trade-off between feature point invariance and discriminative power. How should we design for this trade-off?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{A2:} Your answer here.

\textbf{Required characteristics}
\begin{itemize}
  \item Repeatability : Even in various changes in images such as geometric transformation or illumination change, same point in real world should be able to be detected as same by the feature point descriptor.
  \item Distinguishability (Descriminative power) : Different points should be able to be distinguished as different points by the descriptor.
  \item Good performance in terms of computation : Feature point shouldn't be expensive to calculate.
\end{itemize}

\textbf{Trade-off between feature point invariance and discriminative power} \\
Feature point invariance is required for achieving repeatability, and discriminative power is required for achieving distinguishability. However, those two has trade off. Descriptors with high invariance (extreme example can be constant descriptor) have low discriminative power, and descriptors with high discriminative power can have very low repeatability.
Optimal balance between those two trade-off can be achieved by careful tuning, or machine learning.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Please leave the pagebreak
\pagebreak
\paragraph{Q3:} In the Harris corner detector, what do the eigenvalues of the `M' second moment matrix represent? Discuss both how they relate to image intensity and how we can interpret them geometrically.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{A3:} Your answer here.

In order to detect corner or edges, we need to know change of intensity in image.
For given image, change in intensity of image of window $w(x, y)$ for shift $(u, v)$ is calculated as follows.
\begin{displaymath}
    E(u, v) = \sum_{x, y}w(x, y)[I(x + u, y + v) - I(x, y)]^2
\end{displaymath}
In order to know how $E(u, v)$ behaves for small shifts, it can be approximated by a quadratic surface for efficiency of calculation. By second-order taylor expansion, it can be simplifies to
\begin{displaymath}
    E(u, v)
    \simeq
    \begin{bmatrix}
    u & v
    \end{bmatrix}
    M
    \begin{bmatrix}
    u \\
    v
    \end{bmatrix}
\end{displaymath}
where
\begin{displaymath}
    M = \sum_{x, y}w(x, y)
    \begin{bmatrix}
    I_x^2 & I_xI_y \\
    I_xI_y & I_y^2
    \end{bmatrix}
\end{displaymath}
So, it can be said that the second moment M shows the image derivatives in x and y direction. \\
In order to see how the eigenvalues of M relate to image intensity by geometric interpretation, consider the horizontal slice of E:
\begin{displaymath}
    \begin{bmatrix}
    u & v
    \end{bmatrix}
    M
    \begin{bmatrix}
    u \\
    v
    \end{bmatrix} = const
\end{displaymath}
which is the equation of an ellipse. \\
Writing the diagonalization of M as follows,
\begin{displaymath}
    M = R^{-1}
    \begin{bmatrix}
    \lambda_1 & 0 \\
    0 & \lambda_2
    \end{bmatrix}
    R
\end{displaymath}
it can be said that the horizontal slice is the equation of the ellipse where long radius is $1 / \sqrt{max(\lambda_1, \lambda_2)}$, lying to the direction of slowest change and short radius is $1 / \sqrt{min(\lambda_1, \lambda_2)}$, lying to the direction of fastest change. \\
How the eigenvalues relate to image intensity can be classified to three cases:
\begin{itemize}
    \item Both $\lambda_1$ and $\lambda_2$ are large positive values : This means that the ellipse is a large circle, thus the image intensity change is large in both directions - a corner.
    \item Only one among $\lambda_1$ and $\lambda_2$ is large : This means that the image intensity change rapidly in only certain direction - an edge.
    \item Both $\lambda_1$ and $\lambda_2$ are close to 0 : This means that the image intensity change is slow in all directions - a flat region.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Please leave the pagebreak
\pagebreak
\paragraph{Q4:} Explain the difference between the Euclidean distance and the cosine similarity metrics between descriptors. What might their geometric interpretations reveal about when each should be used? Given a distance metric, what is a good method for feature descriptor matching and why?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{A4:} Your answer here.

Geometric interpretation of two metrics are : \\ Euclidean distance means the distance between two points, and cosine similarity means the cosine value of the angle between two vectors. \\
So, cosine similarity can be good to be used as a metric when the magnitude of the descriptors doesn't matter. \\
However, if the feature descriptor is normalized (to a unit size vector), euclidean distance between two vectors $\textbf{a}$ and $\textbf{b}$ can be expressed as below:
\begin{equation}
|\textbf{a} - \textbf{b}| = \\
|\textbf{a}|^2 + |\textbf{b}|^2 - 2(\textbf{a}\cdot\textbf{b}) = \\
1 - 2cos\theta
\end{equation}
where $\theta$ is angle between $\textbf{a}$ and $\textbf{b}$.
So, in this situation (size normalized), the relation between two descriptors is linear. Only difference we have to aware when we do the feature matching in this situation is that the two descriptors' possible range is different, and cosine similarity metric increases as the feature "distance" between two points decreases, which is the opposite of euclidean distance metric.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% If you really need extra space, uncomment here and use extra pages after the last question.
% Please refer here in your original answer. Thanks!
\pagebreak
\paragraph{A1 Continued:} Your answer here.

\textbf{Chase} \\
\begin{figure}[!h]
    \centering
    \includegraphics[width=5cm]{Chase1_corner.jpg}
    \includegraphics[width=5cm]{Chase2_corner.jpg}
    \caption{Result of $corner(I,1000)$ on Chase1.jpg and Chase2.jpg each.}
\end{figure} \\
As shown in above figure, Chase2.jpg has blur artifact, which can be caused when camera has moved during exposure. Also, two picture's camera position and rotation is different. So, if the feature descriptor is not aware of the rotation or unable to distinguish artifact, it might fail to match.

\textbf{LaddObservatory} \\
\begin{figure}[!h]
    \centering
    \includegraphics[width=5cm]{LaddObservatory1_corner.jpg}
    \includegraphics[width=5cm]{LaddObservatory2_corner.jpg}
    \caption{Result of $corner(I,1000)$ on LaddObservatory1.jpg and LaddObservatory2.jpg each.}
\end{figure} \\
As shown in above figure, LaddObservatory2.jpg has people in the picture unlike LaddObservatory1.jpg, and it is casuing occlusion. Also, distance from camera to the object is very different in two pictures. So, if the feature descriptor is not scale invariant, it might fail to match. \\

\end{document}
